FROM ubuntu:22.04

# Install dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    curl \
    git \
    build-essential \
    cmake \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Create model directory
RUN mkdir -p /app/model

# Download model files from Hugging Face
RUN echo "ðŸ“¥ Downloading model files from Hugging Face..."
RUN curl -L -o /app/model/model-00001-of-00003.safetensors "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/model-00001-of-00003.safetensors"
RUN curl -L -o /app/model/model-00002-of-00003.safetensors "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/model-00002-of-00003.safetensors"
RUN curl -L -o /app/model/model-00003-of-00003.safetensors "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/model-00003-of-00003.safetensors"
RUN curl -L -o /app/model/config.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/config.json"
RUN curl -L -o /app/model/tokenizer.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/tokenizer.json"
RUN curl -L -o /app/model/tokenizer_config.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/tokenizer_config.json"
RUN curl -L -o /app/model/model.safetensors.index.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/model.safetensors.index.json"
RUN curl -L -o /app/model/generation_config.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/generation_config.json"
RUN curl -L -o /app/model/special_tokens_map.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/special_tokens_map.json"
RUN curl -L -o /app/model/added_tokens.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/added_tokens.json"
RUN curl -L -o /app/model/merges.txt "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/merges.txt"
RUN curl -L -o /app/model/vocab.json "https://huggingface.co/Amritansh8/qwen-career-optimized/resolve/main/vocab.json"
RUN echo "âœ… Model files downloaded successfully"

# Install Python dependencies
RUN pip3 install --no-cache-dir \
    llama-cpp-python \
    fastapi \
    uvicorn \
    transformers \
    torch

# Copy Python server code
COPY server.py /app/server.py

# Make the server executable
RUN chmod +x /app/server.py

# Expose port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:11434/ || exit 1

# Start the server
CMD ["python3", "/app/server.py"]